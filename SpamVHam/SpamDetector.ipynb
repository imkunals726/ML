{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.parser import BytesParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpamDetector.ipynb  \u001b[1m\u001b[36measy_ham\u001b[m\u001b[m/           \u001b[1m\u001b[36mspam\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAM_PATH='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_ham_emails = [ load_email(False,email) for email in os.listdir('easy_ham/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emails = [ load_email(True,email) for email in os.listdir('spam/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path <rssfeeds@example.com>\n",
      "Delivered-To yyyy@localhost.example.com\n",
      "Received from localhost (jalapeno [127.0.0.1])\tby jmason.org (Postfix) with ESMTP id AE79816F16\tfor <jm@localhost>; Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received from localhost (jalapeno [127.0.0.1])\tby jmason.org (Postfix) with ESMTP id AE79816F16\tfor <jm@localhost>; Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received from localhost (jalapeno [127.0.0.1])\tby jmason.org (Postfix) with ESMTP id AE79816F16\tfor <jm@localhost>; Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Message-Id <200209300801.g8U81fg21359@dogma.slashnull.org>\n",
      "To yyyy@example.com\n",
      "From gamasutra <rssfeeds@example.com>\n",
      "Subject Priceless Rubens works stolen in raid on mansion\n",
      "Date Mon, 30 Sep 2002 08:01:41 -0000\n",
      "Content-Type text/plain; encoding=\"utf-8\"\n",
      "Lines 6\n",
      "X-Spam-Status No, hits=-527.4 required=5.0\ttests=AWL,DATE_IN_PAST_03_06,T_URI_COUNT_0_1\tversion=2.50-cvs\n",
      "X-Spam-Level \n"
     ]
    }
   ],
   "source": [
    "em = easy_ham_emails[0]\n",
    "for key in em.keys():\n",
    "    print(key,em[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urlextract\n",
      "  Downloading urlextract-0.14.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: idna in /Users/Kunal/anaconda3/lib/python3.6/site-packages (from urlextract) (2.8)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting uritools\n",
      "  Downloading uritools-3.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: appdirs, uritools, urlextract\n",
      "Successfully installed appdirs-1.4.3 uritools-3.0.0 urlextract-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam_emails + easy_ham_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0] * len(spam_emails) + [1] * len(easy_ham_emails) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'im', 'kunal', '', 'do', 'you', 'know', 'me', '']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "table\n",
    "[ w.translate(table) for w in 'Hi i\"m kunal . do you know me ? '.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailToWordCounter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,lowercase=True, remove_punctuation=True, replace_url=True, replace_number=True):\n",
    "        self.lowercase=lowercase\n",
    "        self.remove_punctuation=remove_punctuation\n",
    "        self.replace_url=replace_url\n",
    "        self.replace_number=replace_number\n",
    "        self.url_extractor = urlextract.URLExtract()\n",
    "        self.count_vectorizer = CountVectorizer()\n",
    "        \n",
    "        \n",
    "    def do_remove_puctuation(self,text):\n",
    "        import string\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        vector = [ w.translate(table) for w in text.split()]\n",
    "        vector = [ word for word in vector if word != '' ]\n",
    "        return ' '.join(vector)\n",
    "    \n",
    "    def do_replace_numbers(self, text):\n",
    "        text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "        return text\n",
    "    \n",
    "    def do_replace_url(self, text):\n",
    "        urls = self.url_extractor.find_urls(text)\n",
    "\n",
    "        for url in urls:\n",
    "            text = text.replace(url, 'URL')\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    def preprocess(self,X):\n",
    "        new_X=[]\n",
    "        for email in X:\n",
    "            email_text=email_to_text(email)\n",
    "              \n",
    "            if self.lowercase:email_text = email_text.lower()\n",
    "                \n",
    "            if self.replace_url:email_text=self.do_replace_url(email_text)\n",
    "                \n",
    "            if self.replace_number:email_text=self.do_replace_numbers(email_text)\n",
    "                \n",
    "            if self.remove_punctuation:email_text=self.do_remove_puctuation(email_text)\n",
    "            \n",
    "            new_X.append(email_text)\n",
    "        \n",
    "        return new_X\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "                    \n",
    "        new_X = self.preprocess(X)\n",
    "        \n",
    "        self.count_vectorizer.fit(new_X) \n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        new_X = self.preprocess(X)\n",
    "        \n",
    "        return self.count_vectorizer.transform(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_to_word_transformer = EmailToWordCounter()\n",
    "X_train_transformed=email_to_word_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr_reg = LogisticRegression()\n",
    "lr_reg.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= lr_reg.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 360,    2],\n",
       "       [   0, 1927]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed=email_to_word_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<763x31179 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 82650 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_reg.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9855832241153342"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130,   9],\n",
       "       [  2, 622]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912350597609562"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "predictor = Pipeline([\n",
    "    ('preparator', EmailToWordCounter()),\n",
    "    ('predictor', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preparator', EmailToWordCounter(lowercase=True, remove_punctuation=True,\n",
       "          replace_number=True, replace_url=True)), ('predictor', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857369255150554"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967948717948718"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
