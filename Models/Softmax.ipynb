{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris= load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris['data'][:,(2,3)]\n",
    "y=iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_new = np.c_[np.ones([len(X), 1]), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(X)\n",
    "rnd_indices = np.random.permutation(total_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(total_size * 0.2)\n",
    "val_size = int(total_size * 0.2)\n",
    "train_size = int(total_size * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_new[rnd_indices[:train_size]]\n",
    "X_val = X_new[rnd_indices[train_size:-test_size] ]\n",
    "X_test = X_new[rnd_indices[test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[rnd_indices[:train_size]]\n",
    "y_val = y[rnd_indices[train_size:-test_size] ]\n",
    "y_test = y[rnd_indices[test_size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    return exps / exp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot_encode(y):\n",
    "    m=len(y)\n",
    "    n_classes=y.max() + 1\n",
    "    y_one_hot = np.zeros((m,n_classes))\n",
    "    y_one_hot[np.arange(m),y] = 1\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_one_hot_encode(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_one_hot_encode(y_train)\n",
    "y_val = to_one_hot_encode(y_val)\n",
    "y_test = to_one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]\n",
    "n_outputs=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs,n_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now here comes the hardest part: training! Theoretically, it's simple: it's just a matter of translating the math equations into Python code. But in practice, it can be quite tricky: in particular, it's easy to mix up the order of the terms, or the indices. You can even end up with code that looks like it's working but is actually not computing exactly the right thing. When unsure, you should write down the shape of each term in the equation and make sure the corresponding terms in your code match closely. It can also help to evaluate each term independently and print them out. The good news it that you won't have to do this everyday, since all this is well implemented by Scikit-Learn, but it will help you understand what's going on under the hood.\n",
    "\n",
    "So the equations we will need are the cost function:\n",
    "\n",
    "$J(\\mathbf{\\Theta}) = \\dfrac{1}{m} \\sum\\limits{i=1}^{m} { \\sum\\limits{k=1}^{K}{y_k^{(i)}\\log\\left(\\hat{p}_k^{(i)}\\right)} }$\n",
    "And the equation for the gradients:\n",
    "\n",
    "$\\nabla_{\\mathbf{\\theta}^{(k)}} \\, J(\\mathbf{\\Theta}) = \\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{ \\left ( \\hat{p}^{(i)}_k - y_k^{(i)} \\right ) \\mathbf{x}^{(i)}}$\n",
    "\n",
    "Note that $\\log\\left(\\hat{p}_k^{(i)}\\right)$ may not be computable if $\\hat{p}_k^{(i)} = 0$. So we will add a tiny value $\\epsilon$ to $\\log\\left(\\hat{p}_k^{(i)}\\right)$ to avoid getting nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.225258233666248\n",
      "500 0.7437784012968843\n",
      "1000 0.6276448772950922\n",
      "1500 0.5579846694734841\n",
      "2000 0.511893151682225\n",
      "2500 0.4788211463479246\n",
      "3000 0.45359027596758156\n",
      "3500 0.4334394978980776\n",
      "4000 0.4167805541015985\n",
      "4500 0.4026389227094392\n",
      "5000 0.3903836007492423\n"
     ]
    }
   ],
   "source": [
    "eta = 0.01\n",
    "epochs=5001\n",
    "theta = np.random.randn(n_inputs,n_outputs)\n",
    "epsilon=1e-7\n",
    "m =len(X_train)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    soft_max_scores = X_train.dot(theta)\n",
    "    Y_proba = softmax(soft_max_scores)\n",
    "    loss = -np.mean( np.sum(y_train * np.log(Y_proba + epsilon ) , axis =1 ) )\n",
    "    error = Y_proba - y_train\n",
    "    if epoch % 500 == 0:\n",
    "        print(epoch, loss)\n",
    "    grad = 1/m * X_train.T.dot(error)\n",
    "    theta = theta - eta *grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3655896 , -0.59552686, -2.51758943],\n",
       "       [-1.73073134, -0.60592296, -0.97419478],\n",
       "       [-1.54670082, -0.34553142,  2.01757374]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_soft_max = X_val.dot(theta)\n",
    "y_val_prob = softmax(val_soft_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_acutal = np.argmax(y_val, axis = 1)\n",
    "y_val_pred = np.argmax(y_val_prob, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( y_val_acutal == y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.470138484888197\n",
      "500 0.8604052467241752\n",
      "1000 0.6818280052802425\n",
      "1500 0.6132498830555185\n",
      "2000 0.5814886286157532\n",
      "2500 0.5638263785048387\n",
      "3000 0.5524943944883337\n",
      "3500 0.5444807617886854\n",
      "4000 0.5384459499436459\n",
      "4500 0.5337085681619916\n",
      "5000 0.5298799051654057\n",
      "5500 0.5267179999380633\n",
      "6000 0.5240624898599257\n",
      "6500 0.5218021550305435\n",
      "7000 0.5198571433291109\n",
      "7500 0.5181684909872433\n",
      "8000 0.516691601215912\n",
      "8500 0.515392022718504\n",
      "9000 0.5142426339863428\n",
      "9500 0.5132217192906859\n",
      "10000 0.5123116263470308\n"
     ]
    }
   ],
   "source": [
    "eta = .01\n",
    "epochs=10001\n",
    "theta = np.random.randn(n_inputs,n_outputs)\n",
    "epsilon=1e-7\n",
    "alpha = 0.1\n",
    "m =len(X_train)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    soft_max_scores = X_train.dot(theta)\n",
    "    Y_proba = softmax(soft_max_scores)\n",
    "    loss = -np.mean( np.sum(y_train * np.log(Y_proba + epsilon ) , axis =1 ) )\n",
    "    l2_loss = 1/2 *np.sum(np.square(theta[1:]))\n",
    "    loss += (alpha *l2_loss)\n",
    "    error = Y_proba - y_train\n",
    "    if epoch % 500 == 0:\n",
    "        print(epoch, loss)\n",
    "    grad = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * theta[1:]]\n",
    "    theta = theta - eta *grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_soft_max = X_val.dot(theta)\n",
    "y_val_pred = softmax(y_val_soft_max)\n",
    "\n",
    "y_val_pred = np.argmax(y_val_pred, axis = 1)\n",
    "y_val_act = np.argmax(y_val,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_val_pred==y_val_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.80126265, -0.9263831 , -2.94646634],\n",
       "       [-0.85291029,  0.30455043,  0.53971364],\n",
       "       [-0.40556752, -0.11221168,  0.51504657]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_soft_max = X_test.dot(theta)\n",
    "y_test_pred = softmax(y_test_soft_max)\n",
    "\n",
    "y_test_pred = np.argmax(y_test_pred, axis = 1)\n",
    "y_test_act = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test_pred==y_test_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test_pred==y_test_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
